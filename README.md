
# Gemini Prompt Lab (Python)

A small, production-style **promptâ€‘engineering lab** for Googleâ€™s Gemini API.  
It lets you:

- Try **multiple prompt variants** (baseline, rubric, fewâ€‘shot, JSONâ€‘only)
- Inspect the **exact prompt** sent to the model (UI)
- **Evaluate and score** outputs on test cases (CSV/JSON artifacts)
- Run from a clean **CLI** or a sleek **Streamlit UI** with a playful GENAI mascot âœ¨

---

## âœ¨ Features

- **Official SDK** â€” uses the maintained `google-genai` client
- **Variants** â€” baseline / rubric / fewâ€‘shot / JSONâ€‘only classification
- **Scoring** â€” simple heuristics:
  - Summaries: wordâ€‘limit compliance + keyword presence
  - Classification: valid JSON + correct label
- **Artifacts** â€” writes `artifacts/results.csv` and `artifacts/results.json`
- **UI** â€” Streamlit app with a welcome modal, animated mascot, sideâ€‘byâ€‘side variant compare, token counts, and oneâ€‘click downloads
- **CLI** â€” Typerâ€‘based, fast and scriptable

---

## ðŸ—‚ Repo Structure

```
gemini-prompt-lab/
â”œâ”€ src/prompt_lab/
â”‚  â”œâ”€ genai_client.py        # Gemini wrapper (loads .env, token count, text gen)
â”‚  â”œâ”€ cli.py                 # Typer CLI (run/tokens)
â”‚  â””â”€ __init__.py
â”œâ”€ prompts/
â”‚  â””â”€ variants.yaml          # all prompt variants live here
â”œâ”€ data/
â”‚  â””â”€ cases.json             # test cases (summarize/classify)
â”œâ”€ eval/
â”‚  â””â”€ run_eval.py            # runs variants on cases, scores, writes artifacts
â”œâ”€ artifacts/                # generated: results.csv / results.json
â”œâ”€ assets/
â”‚  â””â”€ styles.css             # UI styling + mascot animations
â”œâ”€ streamlit_app.py          # UI to inspect and run variants
â”œâ”€ requirements.txt
â”œâ”€ pyproject.toml            # package metadata; exposes CLI command `gpl`
â”œâ”€ .env                      # your GOOGLE_API_KEY (never commit)
â”œâ”€ .gitignore
â””â”€ README.md
```

---

## âœ… Prerequisites

- Python **3.9+**
- A **Google AI Studio** API key (free tier works)

Create a `.env` file in the project root (same folder as `streamlit_app.py`):

```
GOOGLE_API_KEY=your_real_key_here
```

> `.env` is ignored by Git. Never commit secrets.

---

## ðŸš€ Quick Start

### 1) Create & activate a virtual env

**Windows (PowerShell)**
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

**macOS / Linux**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 2) Install deps and the package (editable)

```bash
pip install -r requirements.txt
pip install -e .
```

### 3) Sanity check (CLI)

```bash
python -m prompt_lab.cli run --prompt "Say hello in 5 words."
```

You should see a short response printed to the console.

---

## ðŸ§° CLI Usage

After `pip install -e .`, you can use either the module or the console script.

**Module form (always works)**
```bash
python -m prompt_lab.cli run --prompt "List three crisp tips for writing prompts."
python -m prompt_lab.cli run --prompt "Rewrite this to be concise: We will reschedule the launch..." --system ./prompts/system.md
python -m prompt_lab.cli tokens "Explain cosine similarity in one sentence."
```

**Console script (`gpl`)**  
*(If `gpl` isnâ€™t found, ensure your venv is active and reâ€‘run `pip install -e .`.)*
```bash
gpl run --prompt "List three crisp tips for writing prompts."
gpl run --prompt "Rewrite this to be concise: We will reschedule the launch..." --system ./prompts/system.md --show-tokens
gpl tokens "Explain cosine similarity in one sentence."
```

**Useful flags**
- `--prompt` : text **OR** path to a `.txt` file
- `--system` : optional system prompt file (Markdown)
- `--model` : override model (default is `gemini-1.5-flash`)
- `--temp` / `--max-tokens`
- `--show-tokens` : prints integer token count for the prompt

---

## ðŸ–¥ Streamlit UI

Run a modern UI to compare variants and inspect each **rendered prompt**.

```bash
pip install streamlit     # if not installed yet
streamlit run ./streamlit_app.py
```

What youâ€™ll get:
- **Welcome modal** with a friendly GENAI mascot (animated wander â†’ center)
- **Variants** multiâ€‘select (baseline / rubric / fewshot / json_classify)
- **Cases** dropdown (from `data/cases.json`)
- Editable input, sliders for temperature & max tokens
- Output cards with tabs: **Response**, **Rendered prompt**, **Metrics**, **Download**
- Prompt & output token counts, plus CSV/JSON downloads

> Tip: If you ever get an API key error in the UI, ensure `.env` contains `GOOGLE_API_KEY=...` and restart Streamlit.

---

## ðŸ§ª Evaluation Harness

Run all variants across all cases and write CSV/JSON artifacts:

```bash
python ./eval/run_eval.py
```

Outputs:
- `artifacts/results.csv` â€“ easy to sort/filter
- `artifacts/results.json` â€“ raw structured results

**Scoring (simple, transparent)**
- **Summaries**
  - `score_len`: 1.0 if within `max_words` (linear penalty if over)
  - `score_keywords`: fraction of required keywords present
  - `total_score` = average of the two
- **Classification**
  - `ok_json`: 1.0 if valid JSON with expected keys
  - `score_label`: 1.0 if label matches expected
  - `total_score` = average of the two

These are quick guardrails for **prompt iteration**, not absolute accuracy metrics.

---

## ðŸ§© Prompt Variants & Cases

All variants live in **`prompts/variants.yaml`**. Each has:
- `id`, `title`
- optional `applies_to` (`[summarize, classify]`)
- optional `system` instruction
- `prompt_template` (uses `{task}` and `{input}`)
- optional `few_shots` (inline examples)
- optional `response_mime_type` (e.g., `application/json`)

Cases live in **`data/cases.json`** and look like:

```json
{
  "id": "sum_1",
  "type": "summarize",
  "task": "Summarize the following in one sentence.",
  "input": "The product launch moved from Sep 30 to Oct 7 due to QA issues.",
  "max_words": 25,
  "keywords": ["launch", "Oct 7"]
}
```

---

## âž• Add Your Own Variant

Append a new block to `prompts/variants.yaml`, e.g.:

```yaml
- id: grounded
  title: Grounded w/ Search (citations)
  applies_to: [summarize]
  system: |-
    You are a precise assistant. Cite sources.
  prompt_template: |-
    Answer briefly and cite sources.
    Question:
    {input}
```

> You can also extend `genai_client.py` to enable Google Search grounding via SDK tools, then use it in this variant.

---

## ðŸ§  Design Notes (Explain Like Iâ€™m Five)

- **Cases** = small tasks (summarize/classify).
- **Variants** = different ways to ask the model (baseline, rules/rubric, exampleâ€‘driven, JSONâ€‘only).
- **UI** = pick a case + variant(s), click **Run**, and see the answer **and** the exact prompt we sent.
- **Eval** = run everything automatically and write a CSV so you can compare and improve.

> In one line: this repo proves you can **design, run, and measure** prompts â€” not just chat.

---

## ðŸ§¯ Troubleshooting

**`gpl : not recognized`**  
Venv not active or console script not installed. Run:
```bash
source .venv/bin/activate      # or .\.venv\Scripts\Activate.ps1 on Windows
pip install -e .
gpl --help
```

**Auth errors / missing key**  
Ensure `.env` contains `GOOGLE_API_KEY=...`. You can also set it just for this shell:
```bash
export GOOGLE_API_KEY="your_real_key"   # PowerShell: $env:GOOGLE_API_KEY='...'
```

**`ModuleNotFoundError: prompt_lab`**  
Reinstall in editable mode: `pip install -e .`

**Windows PowerShell hereâ€‘strings show `>>` prompts**  
Save the snippet to a `.py` file and run `python file.py`, or ensure the hereâ€‘string closing `'@` is at **column 1** (no spaces).

**JSON/YAML encoding issues**  
This repo reads with `utfâ€‘8â€‘sig` to tolerate BOM. If editing on Windows Notepad, prefer UTFâ€‘8 (no BOM).

---

## ðŸ—º Roadmap

- Add a **grounded** variant (Google Search tool + citations)
- Add **schemaâ€‘validated JSON** outputs for structured tasks
- Expand **cases** (longer texts, harder constraints)
- Sideâ€‘byâ€‘side UI compare view + export to CSV

---

## ðŸ“„ License

MIT. See `LICENSE`.

---

ðŸ™Œ Credits & documentation

Google GenAI SDK (google-genai)
Overview & Quickstart â€” https://ai.google.dev/gemini-api/docs

Text generation â€” https://ai.google.dev/gemini-api/docs/text-generation

Counting tokens â€” https://ai.google.dev/gemini-api/docs/tokens

Python SDK (PyPI) â€” https://pypi.org/project/google-genai/

Google AI Studio (API keys & console) â€” https://aistudio.google.com/

Streamlit (UI framework)
Docs â€” https://docs.streamlit.io/

Appearance & Theming â€” https://docs.streamlit.io/develop/concepts/design/streamlit-appearance

Typer (CLI framework) â€” https://typer.tiangolo.com/

Rich (console formatting) â€” https://rich.readthedocs.io/

PyYAML (YAML parsing) â€” https://pyyaml.org/wiki/PyYAMLDocumentation

python-dotenv (env loading) â€” https://pypi.org/project/python-dotenv/

Packaging / editable installs â€” https://packaging.python.org/en/latest/tutorials/installing-packages/#installing-from-a-local-src-tree

YAML spec â€” https://yaml.org/spec/

Icons/emoji â€” Unicode / Twemoji
